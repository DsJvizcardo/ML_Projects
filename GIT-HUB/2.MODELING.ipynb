{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-24T01:59:54.321959Z",
     "start_time": "2025-01-24T01:53:40.663119Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Cargar el dataset seleccionado\n",
    "selected_features = pd.read_csv(\"selected_features_rfe_optimized_100.csv\")\n",
    "\n",
    "# Separar las características (X) y la variable objetivo (y)\n",
    "X = selected_features.drop(columns=['label'])  # Características\n",
    "y = selected_features['label']  # Variable objetivo\n",
    "\n",
    "# Imputar valores faltantes\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "# Escalar los datos\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_imputed)\n",
    "\n",
    "# Dividir el dataset en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Parámetros para la búsqueda de hiperparámetros\n",
    "param_grid = {\n",
    "    'L2 (Ridge)': {\n",
    "        'model': LogisticRegression(penalty='l2', solver='saga', max_iter=1000, multi_class='multinomial', random_state=42),\n",
    "        'param_grid': {'C': [0.01, 0.1, 1, 10, 100]}\n",
    "    },\n",
    "    'L1 (Lasso)': {\n",
    "        'model': LogisticRegression(penalty='l1', solver='saga', max_iter=1000, multi_class='multinomial', random_state=42),\n",
    "        'param_grid': {'C': [0.01, 0.1, 1, 10, 100]}\n",
    "    },\n",
    "    'Elastic-Net': {\n",
    "        'model': LogisticRegression(penalty='elasticnet', solver='saga', max_iter=1000, multi_class='multinomial', random_state=42),\n",
    "        'param_grid': {'C': [0.01, 0.1, 1, 10, 100], 'l1_ratio': [0.1, 0.5, 0.9]}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Resultados de cada modelo\n",
    "for reg_name, config in param_grid.items():\n",
    "    print(f\"\\nOptimizando modelo con regularización: {reg_name}\")\n",
    "    model = config['model']\n",
    "    param_grid = config['param_grid']\n",
    "\n",
    "    # GridSearchCV para optimización\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring='f1_weighted', cv=5, n_jobs=-1, verbose=2)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Mejor modelo\n",
    "    best_model = grid_search.best_estimator_\n",
    "    print(f\"Mejores hiperparámetros para {reg_name}: {grid_search.best_params_}\")\n",
    "\n",
    "    # Predicción en el conjunto de prueba\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    # Calcular métricas\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')  # Promedio ponderado para multiclase\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"F1-Score (weighted): {f1:.4f}\")\n",
    "\n",
    "    # Mostrar clasificación detallada\n",
    "    print(\"Reporte de clasificación:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Importancia de las variables (coeficientes)\n",
    "    if hasattr(best_model, 'coef_'):\n",
    "        print(\"Importancia de las variables (coeficientes absolutos):\")\n",
    "        importance = pd.DataFrame({\n",
    "            'Variable': X.columns,\n",
    "            'Coeficiente': abs(best_model.coef_).mean(axis=0)  # Media de los coeficientes para multiclase\n",
    "        }).sort_values(by='Coeficiente', ascending=False)\n",
    "        print(importance.head(10))  # Mostrar las 10 más importantes\n",
    "        # Exportar importancias a CSV\n",
    "        importance.to_csv(f\"100_variable_importance_{reg_name.replace(' ', '_')}.csv\", index=False)\n",
    "        print(f\"Importancias exportadas a 'variable_importance_{reg_name.replace(' ', '_')}.csv'\")\n",
    "\n",
    "print(\"\\nOptimización y evaluación completadas.\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizando modelo con regularización: L2 (Ridge)\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros para L2 (Ridge): {'C': 0.1}\n",
      "Accuracy: 0.9810\n",
      "F1-Score (weighted): 0.9809\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.99      1.00      1.00       368\n",
      "         2.0       1.00      1.00      1.00       322\n",
      "         3.0       1.00      0.99      1.00       296\n",
      "         4.0       0.95      0.95      0.95       386\n",
      "         5.0       0.96      0.96      0.96       412\n",
      "         6.0       0.99      1.00      1.00       422\n",
      "\n",
      "    accuracy                           0.98      2206\n",
      "   macro avg       0.98      0.98      0.98      2206\n",
      "weighted avg       0.98      0.98      0.98      2206\n",
      "\n",
      "Importancia de las variables (coeficientes absolutos):\n",
      "                                             Variable  Coeficiente\n",
      "21  body_gyro_x__agg_autocorrelation__f_agg_\"mean\"...     0.299714\n",
      "92                total_acc_y__number_crossing_m__m_0     0.296229\n",
      "1   body_acc_x__time_reversal_asymmetry_statistic_...     0.224568\n",
      "6    body_acc_x__fft_coefficient__attr_\"abs\"__coeff_4     0.216565\n",
      "62  total_acc_x__fft_coefficient__attr_\"abs\"__coeff_4     0.215839\n",
      "24  body_gyro_x__fft_coefficient__attr_\"abs\"__coeff_0     0.213536\n",
      "35  body_gyro_y__fft_coefficient__attr_\"abs\"__coeff_6     0.210890\n",
      "68  total_acc_x__agg_linear_trend__attr_\"intercept...     0.207128\n",
      "46  body_gyro_z__fft_coefficient__attr_\"abs\"__coeff_6     0.206985\n",
      "81                total_acc_y__autocorrelation__lag_7     0.205162\n",
      "Importancias exportadas a 'variable_importance_L2_(Ridge).csv'\n",
      "\n",
      "Optimizando modelo con regularización: L1 (Lasso)\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\usuario\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros para L1 (Lasso): {'C': 1}\n",
      "Accuracy: 0.9814\n",
      "F1-Score (weighted): 0.9814\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00       368\n",
      "         2.0       0.99      1.00      1.00       322\n",
      "         3.0       1.00      0.99      1.00       296\n",
      "         4.0       0.95      0.95      0.95       386\n",
      "         5.0       0.96      0.95      0.96       412\n",
      "         6.0       1.00      1.00      1.00       422\n",
      "\n",
      "    accuracy                           0.98      2206\n",
      "   macro avg       0.98      0.98      0.98      2206\n",
      "weighted avg       0.98      0.98      0.98      2206\n",
      "\n",
      "Importancia de las variables (coeficientes absolutos):\n",
      "                                             Variable  Coeficiente\n",
      "92                total_acc_y__number_crossing_m__m_0     0.409791\n",
      "26  body_gyro_x__fft_coefficient__attr_\"abs\"__coeff_9     0.405229\n",
      "21  body_gyro_x__agg_autocorrelation__f_agg_\"mean\"...     0.385587\n",
      "24  body_gyro_x__fft_coefficient__attr_\"abs\"__coeff_0     0.370050\n",
      "35  body_gyro_y__fft_coefficient__attr_\"abs\"__coeff_6     0.358703\n",
      "2                               body_acc_x__c3__lag_1     0.344479\n",
      "85  total_acc_y__fft_coefficient__attr_\"abs\"__coeff_4     0.316181\n",
      "1   body_acc_x__time_reversal_asymmetry_statistic_...     0.302006\n",
      "58  total_acc_x__agg_autocorrelation__f_agg_\"var\"_...     0.301846\n",
      "43                body_gyro_z__autocorrelation__lag_9     0.297415\n",
      "Importancias exportadas a 'variable_importance_L1_(Lasso).csv'\n",
      "\n",
      "Optimizando modelo con regularización: Elastic-Net\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros para Elastic-Net: {'C': 0.1, 'l1_ratio': 0.1}\n",
      "Accuracy: 0.9801\n",
      "F1-Score (weighted): 0.9800\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.99      1.00      1.00       368\n",
      "         2.0       0.99      1.00      1.00       322\n",
      "         3.0       1.00      0.99      0.99       296\n",
      "         4.0       0.95      0.95      0.95       386\n",
      "         5.0       0.96      0.95      0.95       412\n",
      "         6.0       1.00      1.00      1.00       422\n",
      "\n",
      "    accuracy                           0.98      2206\n",
      "   macro avg       0.98      0.98      0.98      2206\n",
      "weighted avg       0.98      0.98      0.98      2206\n",
      "\n",
      "Importancia de las variables (coeficientes absolutos):\n",
      "                                             Variable  Coeficiente\n",
      "21  body_gyro_x__agg_autocorrelation__f_agg_\"mean\"...     0.288441\n",
      "92                total_acc_y__number_crossing_m__m_0     0.285030\n",
      "1   body_acc_x__time_reversal_asymmetry_statistic_...     0.202166\n",
      "68  total_acc_x__agg_linear_trend__attr_\"intercept...     0.192570\n",
      "24  body_gyro_x__fft_coefficient__attr_\"abs\"__coeff_0     0.184946\n",
      "58  total_acc_x__agg_autocorrelation__f_agg_\"var\"_...     0.184902\n",
      "6    body_acc_x__fft_coefficient__attr_\"abs\"__coeff_4     0.183857\n",
      "52                               total_acc_x__minimum     0.183445\n",
      "62  total_acc_x__fft_coefficient__attr_\"abs\"__coeff_4     0.183007\n",
      "2                               body_acc_x__c3__lag_1     0.180541\n",
      "Importancias exportadas a 'variable_importance_Elastic-Net.csv'\n",
      "\n",
      "Optimización y evaluación completadas.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T02:34:06.048344Z",
     "start_time": "2025-01-24T02:34:02.271315Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el nuevo dataset donde solo están las variables X\n",
    "new_data = pd.read_csv(\"selected_features_rfe_test.csv\")  # Reemplaza con el nombre de tu archivo\n",
    "data_var_100 = pd.read_csv(\"100_variable_importance_Elastic-Net.csv\")\n",
    "\n",
    "# Filtrar solo las columnas seleccionadas\n",
    "X_new = new_data[X.columns]\n",
    "\n",
    "# Manejar valores faltantes (NaN) imputando con la media\n",
    "X_new_imputed = imputer.transform(X_new)\n",
    "\n",
    "# Escalar las características\n",
    "X_new_scaled = scaler.transform(X_new_imputed)\n",
    "\n",
    "# Realizar las predicciones\n",
    "predictions = best_model.predict(X_new_scaled)\n",
    "\n",
    "# Crear un DataFrame con las predicciones\n",
    "results = pd.DataFrame({\n",
    "    'ID': new_data.index+1,  # Asumimos que el índice es el identificador\n",
    "    'Prediction': predictions\n",
    "})\n",
    "\n",
    "# Exportar el resultado a un archivo CSV\n",
    "results.to_csv(\"predictions_kaggle_100var.csv\", index=False)\n",
    "print(\"Predicciones exportadas a 'predictions_kaggle_100var.csv'.\")\n"
   ],
   "id": "97a8c32eaec86fbb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicciones exportadas a 'predictions_kaggle_100var.csv'.\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T02:37:44.503345Z",
     "start_time": "2025-01-24T02:37:44.486849Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import joblib\n",
    "\n",
    "# Guardar el modelo entrenado\n",
    "joblib.dump(best_model, 'modelo_regresion_logistica_100V.pkl')\n",
    "print(\"Modelo guardado en 'modelo_regresion_logistica.pkl'\")"
   ],
   "id": "21094c47d038e141",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado en 'modelo_regresion_logistica.pkl'\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T02:38:00.181867Z",
     "start_time": "2025-01-24T02:38:00.170627Z"
    }
   },
   "cell_type": "code",
   "source": "X.columns",
   "id": "f0d648c30f7b80d1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['body_acc_x__count_above_mean',\n",
       "       'body_acc_x__time_reversal_asymmetry_statistic__lag_3',\n",
       "       'body_acc_x__c3__lag_1',\n",
       "       'body_acc_x__agg_autocorrelation__f_agg_\"var\"__maxlag_40',\n",
       "       'body_acc_x__spkt_welch_density__coeff_2',\n",
       "       'body_acc_x__ar_coefficient__coeff_2__k_10',\n",
       "       'body_acc_x__fft_coefficient__attr_\"abs\"__coeff_4',\n",
       "       'body_acc_x__fft_coefficient__attr_\"angle\"__coeff_1',\n",
       "       'body_acc_x__friedrich_coefficients__coeff_2__m_3__r_30',\n",
       "       'body_acc_x__agg_linear_trend__attr_\"intercept\"__chunk_len_50__f_agg_\"var\"',\n",
       "       'body_acc_x__lempel_ziv_complexity__bins_3',\n",
       "       'body_acc_y__number_cwt_peaks__n_5',\n",
       "       'body_acc_y__fft_coefficient__attr_\"abs\"__coeff_4',\n",
       "       'body_acc_z__quantile__q_0.4',\n",
       "       'body_acc_z__partial_autocorrelation__lag_2',\n",
       "       'body_acc_z__number_peaks__n_3', 'body_acc_z__number_peaks__n_10',\n",
       "       'body_acc_z__index_mass_quantile__q_0.2',\n",
       "       'body_acc_z__fft_coefficient__attr_\"imag\"__coeff_1',\n",
       "       'body_gyro_x__cid_ce__normalize_True',\n",
       "       'body_gyro_x__autocorrelation__lag_2',\n",
       "       'body_gyro_x__agg_autocorrelation__f_agg_\"mean\"__maxlag_40',\n",
       "       'body_gyro_x__number_peaks__n_3',\n",
       "       'body_gyro_x__ar_coefficient__coeff_1__k_10',\n",
       "       'body_gyro_x__fft_coefficient__attr_\"abs\"__coeff_0',\n",
       "       'body_gyro_x__fft_coefficient__attr_\"abs\"__coeff_1',\n",
       "       'body_gyro_x__fft_coefficient__attr_\"abs\"__coeff_9',\n",
       "       'body_gyro_x__fft_aggregated__aggtype_\"skew\"',\n",
       "       'body_gyro_x__friedrich_coefficients__coeff_0__m_3__r_30',\n",
       "       'body_gyro_x__permutation_entropy__dimension_5__tau_1',\n",
       "       'body_gyro_x__permutation_entropy__dimension_7__tau_1',\n",
       "       'body_gyro_y__autocorrelation__lag_9',\n",
       "       'body_gyro_y__ar_coefficient__coeff_1__k_10',\n",
       "       'body_gyro_y__fft_coefficient__attr_\"abs\"__coeff_1',\n",
       "       'body_gyro_y__fft_coefficient__attr_\"abs\"__coeff_3',\n",
       "       'body_gyro_y__fft_coefficient__attr_\"abs\"__coeff_6',\n",
       "       'body_gyro_y__fft_coefficient__attr_\"abs\"__coeff_7',\n",
       "       'body_gyro_y__fft_coefficient__attr_\"angle\"__coeff_42',\n",
       "       'body_gyro_y__fft_aggregated__aggtype_\"skew\"',\n",
       "       'body_gyro_y__matrix_profile__feature_\"max\"__threshold_0.98',\n",
       "       'body_gyro_z__longest_strike_below_mean',\n",
       "       'body_gyro_z__autocorrelation__lag_5',\n",
       "       'body_gyro_z__autocorrelation__lag_6',\n",
       "       'body_gyro_z__autocorrelation__lag_9',\n",
       "       'body_gyro_z__agg_autocorrelation__f_agg_\"median\"__maxlag_40',\n",
       "       'body_gyro_z__number_peaks__n_10',\n",
       "       'body_gyro_z__fft_coefficient__attr_\"abs\"__coeff_6',\n",
       "       'body_gyro_z__fft_coefficient__attr_\"abs\"__coeff_7',\n",
       "       'body_gyro_z__friedrich_coefficients__coeff_2__m_3__r_30',\n",
       "       'body_gyro_z__agg_linear_trend__attr_\"rvalue\"__chunk_len_50__f_agg_\"var\"',\n",
       "       'body_gyro_z__matrix_profile__feature_\"max\"__threshold_0.98',\n",
       "       'total_acc_x__median', 'total_acc_x__minimum',\n",
       "       'total_acc_x__benford_correlation', 'total_acc_x__quantile__q_0.1',\n",
       "       'total_acc_x__quantile__q_0.2', 'total_acc_x__quantile__q_0.3',\n",
       "       'total_acc_x__quantile__q_0.4',\n",
       "       'total_acc_x__agg_autocorrelation__f_agg_\"var\"__maxlag_40',\n",
       "       'total_acc_x__number_cwt_peaks__n_5',\n",
       "       'total_acc_x__spkt_welch_density__coeff_2',\n",
       "       'total_acc_x__fft_coefficient__attr_\"abs\"__coeff_0',\n",
       "       'total_acc_x__fft_coefficient__attr_\"abs\"__coeff_4',\n",
       "       'total_acc_x__fft_coefficient__attr_\"angle\"__coeff_41',\n",
       "       'total_acc_x__fft_aggregated__aggtype_\"skew\"',\n",
       "       'total_acc_x__fft_aggregated__aggtype_\"kurtosis\"',\n",
       "       'total_acc_x__agg_linear_trend__attr_\"intercept\"__chunk_len_5__f_agg_\"min\"',\n",
       "       'total_acc_x__agg_linear_trend__attr_\"intercept\"__chunk_len_10__f_agg_\"min\"',\n",
       "       'total_acc_x__agg_linear_trend__attr_\"intercept\"__chunk_len_50__f_agg_\"min\"',\n",
       "       'total_acc_x__agg_linear_trend__attr_\"intercept\"__chunk_len_50__f_agg_\"var\"',\n",
       "       'total_acc_x__agg_linear_trend__attr_\"stderr\"__chunk_len_10__f_agg_\"mean\"',\n",
       "       'total_acc_x__ratio_beyond_r_sigma__r_1',\n",
       "       'total_acc_y__root_mean_square',\n",
       "       'total_acc_y__longest_strike_above_mean', 'total_acc_y__maximum',\n",
       "       'total_acc_y__absolute_maximum',\n",
       "       'total_acc_y__symmetry_looking__r_0.05', 'total_acc_y__quantile__q_0.6',\n",
       "       'total_acc_y__quantile__q_0.7', 'total_acc_y__quantile__q_0.8',\n",
       "       'total_acc_y__quantile__q_0.9', 'total_acc_y__autocorrelation__lag_7',\n",
       "       'total_acc_y__agg_autocorrelation__f_agg_\"var\"__maxlag_40',\n",
       "       'total_acc_y__number_peaks__n_10',\n",
       "       'total_acc_y__fft_coefficient__attr_\"abs\"__coeff_0',\n",
       "       'total_acc_y__fft_coefficient__attr_\"abs\"__coeff_4',\n",
       "       'total_acc_y__fft_coefficient__attr_\"angle\"__coeff_1',\n",
       "       'total_acc_y__fft_coefficient__attr_\"angle\"__coeff_12',\n",
       "       'total_acc_y__fft_aggregated__aggtype_\"centroid\"',\n",
       "       'total_acc_y__agg_linear_trend__attr_\"intercept\"__chunk_len_10__f_agg_\"max\"',\n",
       "       'total_acc_y__agg_linear_trend__attr_\"intercept\"__chunk_len_50__f_agg_\"max\"',\n",
       "       'total_acc_y__augmented_dickey_fuller__attr_\"teststat\"__autolag_\"AIC\"',\n",
       "       'total_acc_y__number_crossing_m__m_0',\n",
       "       'total_acc_y__mean_n_absolute_max__number_of_maxima_7',\n",
       "       'total_acc_z__maximum', 'total_acc_z__number_peaks__n_3',\n",
       "       'total_acc_z__agg_linear_trend__attr_\"intercept\"__chunk_len_50__f_agg_\"max\"',\n",
       "       'total_acc_z__lempel_ziv_complexity__bins_100',\n",
       "       'total_acc_z__permutation_entropy__dimension_5__tau_1',\n",
       "       'total_acc_z__permutation_entropy__dimension_6__tau_1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T02:40:29.583818Z",
     "start_time": "2025-01-24T02:40:29.573992Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.DataFrame(X.columns, columns=['Nombres'])\n",
    "# Exportar el DataFrame a un archivo CSV\n",
    "df.to_csv('nombres_variables_100_modelo_regresion_logistica.csv', index=True)\n",
    "print(\"Los nombres se han exportado a nombres.csv.\")"
   ],
   "id": "7d1d0686e4bec61d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los nombres se han exportado a nombres.csv.\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "74f00170fc3ef51f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "SVM",
   "id": "e0d64c016d416ba3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "8d99dfa45c4e0d8e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T02:47:11.052525Z",
     "start_time": "2025-01-24T02:46:13.632170Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "import joblib\n",
    "\n",
    "# Cargar el dataset seleccionado\n",
    "selected_features = pd.read_csv(\"selected_features_rfe_optimized_100.csv\")\n",
    "\n",
    "# Separar las características (X) y la variable objetivo (y)\n",
    "X = selected_features.drop(columns=['label'])  # Características\n",
    "y = selected_features['label']  # Variable objetivo\n",
    "\n",
    "# Imputar valores faltantes\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "# Escalar los datos\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_imputed)\n",
    "\n",
    "# **Reducción de dimensionalidad con PCA**\n",
    "pca = PCA(n_components=0.95)  # Mantener 30 componentes principales\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Guardar el PCA para futuras predicciones\n",
    "joblib.dump(pca, 'pca_transform_100v.pkl')\n",
    "print(\"PCA guardado en 'pca_transform_100v.pkl'.\")\n",
    "\n",
    "# Dividir el dataset en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Definir los parámetros para la búsqueda de hiperparámetros\n",
    "param_grid = {\n",
    "    'kernel': ['linear', 'rbf', 'poly'],  # Tipos de kernel\n",
    "    'C': [0.01, 0.1, 1, 10, 100],  # Regularización\n",
    "    'gamma': ['scale', 'auto'],  # Coeficiente del kernel\n",
    "    'degree': [2, 3, 4]  # Solo aplicable para kernel 'poly'\n",
    "}\n",
    "\n",
    "# Crear el modelo base\n",
    "svm = SVC(decision_function_shape='ovo', random_state=42)\n",
    "\n",
    "# Configurar GridSearchCV con validación cruzada estratificada\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_search = GridSearchCV(estimator=svm, param_grid=param_grid, scoring='f1_weighted', cv=cv, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Mejor modelo\n",
    "best_svm = grid_search.best_estimator_\n",
    "print(f\"Mejores hiperparámetros para SVM: {grid_search.best_params_}\")\n",
    "\n",
    "# Predicción en el conjunto de prueba\n",
    "y_pred = best_svm.predict(X_test)\n",
    "\n",
    "# Calcular métricas\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')  # Promedio ponderado para multiclase\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1-Score (weighted): {f1:.4f}\")\n",
    "\n",
    "# Mostrar clasificación detallada\n",
    "print(\"Reporte de clasificación:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Exportar el modelo optimizado\n",
    "joblib.dump(best_svm, 'svm_model_optimized_100v.pkl')\n",
    "print(\"Modelo SVM optimizado guardado en 'svm_model_optimized.pkl'.\")\n"
   ],
   "id": "2d71433ec230710",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA guardado en 'pca_transform_100v.pkl'.\n",
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n",
      "Mejores hiperparámetros para SVM: {'C': 1, 'degree': 2, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Accuracy: 0.9782\n",
      "F1-Score (weighted): 0.9782\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00       368\n",
      "         2.0       0.99      1.00      1.00       322\n",
      "         3.0       1.00      0.99      1.00       296\n",
      "         4.0       0.94      0.95      0.94       386\n",
      "         5.0       0.96      0.94      0.95       412\n",
      "         6.0       0.99      1.00      0.99       422\n",
      "\n",
      "    accuracy                           0.98      2206\n",
      "   macro avg       0.98      0.98      0.98      2206\n",
      "weighted avg       0.98      0.98      0.98      2206\n",
      "\n",
      "Modelo SVM optimizado guardado en 'svm_model_optimized.pkl'.\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "553d909ccb9bf469"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T02:59:40.353174Z",
     "start_time": "2025-01-24T02:59:36.248247Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Cargar el modelo SVM y el PCA guardados\n",
    "svm_model = joblib.load('svm_model_optimized_100v.pkl')\n",
    "pca = joblib.load('pca_transform_100v.pkl')\n",
    "print(\"Modelo SVM y PCA cargados con éxito.\")\n",
    "\n",
    "# Cargar el nuevo dataset\n",
    "new_data = pd.read_csv(\"selected_features_rfe_test.csv\")  # Reemplaza con el nombre correcto de tu archivo\n",
    "print(\"Nuevo dataset cargado.\")\n",
    "\n",
    "# Asegurarse de que las columnas seleccionadas estén presentes en el nuevo dataset\n",
    "\n",
    "# Seleccionar solo las columnas necesarias\n",
    "X_new = new_data[X.columns]\n",
    "\n",
    "# Manejar valores faltantes en el nuevo dataset\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_new_imputed = imputer.fit_transform(X_new)\n",
    "\n",
    "# Escalar los datos\n",
    "scaler = StandardScaler()\n",
    "X_new_scaled = scaler.fit_transform(X_new_imputed)\n",
    "\n",
    "# Aplicar PCA al nuevo dataset\n",
    "X_new_pca = pca.transform(X_new_scaled)\n",
    "\n",
    "# Hacer predicciones con el modelo SVM cargado\n",
    "predictions = svm_model.predict(X_new_pca)\n",
    "\n",
    "# Crear un DataFrame con las predicciones\n",
    "results = pd.DataFrame({\n",
    "    'ID': new_data.index + 1,  # Asumimos que el índice es el identificador\n",
    "    'Prediction': predictions\n",
    "})\n",
    "\n",
    "# Exportar las predicciones a un archivo CSV\n",
    "results.to_csv(\"predictions_kaggle_svm.csv\", index=False)\n",
    "print(\"Predicciones exportadas a 'predictions_kaggle_svm_100v.csv'.\")\n"
   ],
   "id": "df091d3d1a5fea0b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo SVM y PCA cargados con éxito.\n",
      "Nuevo dataset cargado.\n",
      "Predicciones exportadas a 'predictions_kaggle_svm_100v.csv'.\n"
     ]
    }
   ],
   "execution_count": 49
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
